LLM Prompt-Injection Mini Project Report
=========================================

Summary
-------
- Models evaluated:
- Prompt suite size:
- Defense mode:
- Key findings (1â€“2 bullets):

Setup
-----
- Inference stack:
- Decoding settings:
- Safety protocol:

Evaluation protocol
-------------------
- Benign prompts:
- Injection prompts:
- Metrics: refusal rate, injection success rate, latency

Results (baseline)
-----------------
- Model A:
  - Refusal rate (benign):
  - Injection success rate:
  - Avg latency:
- Model B:
  - Refusal rate (benign):
  - Injection success rate:
  - Avg latency:

Defense results
---------------
- Defense description:
- Changes vs baseline:

Limitations
-----------
- Model scale:
- Prompt coverage:
- Generalization:

Appendix
--------
- Config used:
- Run IDs:
