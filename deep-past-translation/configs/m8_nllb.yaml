# Model 8: NLLB-200 distilled (translation specialist)
model:
  name: facebook/nllb-200-distilled-600M
  max_length: 256
  is_nllb: true

training:
  epochs: 15
  learning_rate: 5.0e-5
  batch_size: 1
  gradient_accumulation: 8
  label_smoothing: 0.1

data:
  use_sentence_align: true
  use_bidirectional: false

output:
  dir: ./models/m8_nllb
