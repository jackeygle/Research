{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":121150,"databundleVersionId":15061024,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":14374989,"sourceType":"datasetVersion","datasetId":9147887},{"sourceId":14376272,"sourceType":"datasetVersion","datasetId":9181082},{"sourceId":14410665,"sourceType":"datasetVersion","datasetId":9203761},{"sourceId":14661932,"sourceType":"datasetVersion","datasetId":9366631},{"sourceId":294611566,"sourceType":"kernelVersion"},{"sourceId":282751,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":239470,"modelId":222398}],"dockerImageVersionId":31236,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom tqdm.auto import tqdm\nimport re\nimport joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.743134Z","iopub.execute_input":"2026-01-29T12:41:45.74347Z","iopub.status.idle":"2026-01-29T12:41:45.748Z","shell.execute_reply.started":"2026-01-29T12:41:45.743442Z","shell.execute_reply":"2026-01-29T12:41:45.747308Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load Models","metadata":{}},{"cell_type":"code","source":"CONFIG = {\n    \"data_path\": \"/kaggle/input/deep-past-initiative-machine-translation/test.csv\",\n    \"models\": [\n        \"/kaggle/input/byt5-base-big-data2\",\n        \"/kaggle/input/byt5-akkadian-model\",\n        \"/kaggle/input/train-gap-all-2/byt5-base-akkadian_gap_setence2\",\n        \"/kaggle/input/final-byt5/byt5-akkadian-optimized-34x\"\n    ],\n    \"model_weights\": [0.995, 0.98, 0.395, 0.70],\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"max_len\": 512,\n    \"batch_size\": 8,\n    \"gen_params\": {\n        \"num_beams\": 8,\n        \"max_new_tokens\": 512,\n        \"length_penalty\": 1.10,\n        \"early_stopping\": True\n    },\n    \"blend_weights\": [0.7, 0.3]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.749511Z","iopub.execute_input":"2026-01-29T12:41:45.749848Z","iopub.status.idle":"2026-01-29T12:41:45.76522Z","shell.execute_reply.started":"2026-01-29T12:41:45.749789Z","shell.execute_reply":"2026-01-29T12:41:45.76438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\n    f\"Blending weights: {CONFIG['blend_weights'][0]*100:.0f}% our model + {CONFIG['blend_weights'][1]*100:.0f}% external\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.76617Z","iopub.execute_input":"2026-01-29T12:41:45.766483Z","iopub.status.idle":"2026-01-29T12:41:45.779045Z","shell.execute_reply.started":"2026-01-29T12:41:45.766452Z","shell.execute_reply":"2026-01-29T12:41:45.778261Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Preprocess & Post-Process","metadata":{}},{"cell_type":"code","source":"def preprocess_transliteration(text):\n    if pd.isna(text): return \"\"\n    processed_text = str(text)\n    processed_text = re.sub(r'(\\.{3,}|…+|……)', '<big_gap>', processed_text)\n    processed_text = re.sub(r'(xx+|\\s+x\\s+)', '<gap>', processed_text)\n    return processed_text\n\ndef postprocess_translation(text):\n    if not isinstance(text, str) or not text.strip(): return \"\"\n    \n    processed_text = text.replace('ḫ', 'h').replace('Ḫ', 'H')\n    sub_map = str.maketrans(\"₀₁₂₃₄₅₆₇₈₉\", \"0123456789\")\n    processed_text = processed_text.translate(sub_map)\n\n    processed_text = re.sub(r'(\\[x\\]|\\(x\\)|\\bx\\b)', '<gap>', processed_text, flags=re.I)\n    processed_text = re.sub(r'(\\.{3,}|…|\\[\\.+\\])', '<big_gap>', processed_text)\n    \n    processed_text = re.sub(r'<gap>\\s*<gap>', ' <big_gap> ', processed_text)\n    processed_text = re.sub(r'<big_gap>\\s*<big_gap>', ' <big_gap> ', processed_text)\n\n    processed_text = re.sub(r'\\((fem|plur|pl|sing|singular|plural|\\?|!)\\.?\\s*\\w*\\)', '', processed_text, flags=re.I)\n\n    processed_text = processed_text.replace('<gap>', '\\x00GAP\\x00').replace('<big_gap>', '\\x00BIG\\x00')\n    \n    # Remove bad characters\n    bad_chars = '!?()\"—–<>⌈⌋⌊[]+ʾ/;'\n    processed_text = processed_text.translate(str.maketrans('', '', bad_chars))\n\n    processed_text = processed_text.replace('\\x00GAP\\x00', ' <gap> ').replace('\\x00BIG\\x00', ' <big_gap> ')\n\n    # Handle fractions\n    frac_map = {\n        r'\\.5\\b': ' ½', r'\\.25\\b': ' ¼', r'\\.75\\b': ' ¾',\n        r'\\.33+\\d*\\b': ' ⅓', r'\\.66+\\d*\\b': ' ⅔'\n    }\n    for pat, rep in frac_map.items():\n        processed_text = re.sub(r'(\\d+)' + pat, r'\\1' + rep, processed_text)\n        processed_text = re.sub(r'\\b0' + pat, rep.strip(), processed_text)\n\n    # Remove repeated words\n    processed_text = re.sub(r'\\b(\\w+)(?:\\s+\\1\\b)+', r'\\1', processed_text)\n    for n in range(4, 1, -1):\n        pat = r'\\b((?:\\w+\\s+){' + str(n-1) + r'}\\w+)(?:\\s+\\1\\b)+'\n        processed_text = re.sub(pat, r'\\1', processed_text)\n\n    return re.sub(r'\\s+', ' ', processed_text).strip().strip('-')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.780555Z","iopub.execute_input":"2026-01-29T12:41:45.780899Z","iopub.status.idle":"2026-01-29T12:41:45.800269Z","shell.execute_reply.started":"2026-01-29T12:41:45.780875Z","shell.execute_reply":"2026-01-29T12:41:45.799502Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Weightings","metadata":{}},{"cell_type":"code","source":"def create_model_soup():\n    total_score = sum(CONFIG['model_weights'])\n    WEIGHTS = [w / total_score for w in CONFIG['model_weights']]\n    \n    # Use the fourth model as the base template\n    template_model = AutoModelForSeq2SeqLM.from_pretrained(CONFIG['models'][3])\n    soup_sd = template_model.state_dict()\n    \n    model_1_sd = AutoModelForSeq2SeqLM.from_pretrained(CONFIG['models'][0]).state_dict()\n    model_2_sd = AutoModelForSeq2SeqLM.from_pretrained(CONFIG['models'][1]).state_dict()\n    model_3_sd = AutoModelForSeq2SeqLM.from_pretrained(CONFIG['models'][2]).state_dict()\n    \n    for key in soup_sd:\n        # Initialize with weighted value from template model (model 4)\n        weighted_value = WEIGHTS[3] * soup_sd[key]\n        norm_factor = WEIGHTS[3]\n        \n        # Add contributions from other models if key exists\n        if key in model_1_sd:\n            weighted_value += WEIGHTS[0] * model_1_sd[key]\n            norm_factor += WEIGHTS[0]\n        if key in model_2_sd:\n            weighted_value += WEIGHTS[1] * model_2_sd[key]\n            norm_factor += WEIGHTS[1]\n        if key in model_3_sd:\n            weighted_value += WEIGHTS[2] * model_3_sd[key]\n            norm_factor += WEIGHTS[2]\n            \n        soup_sd[key] = weighted_value / norm_factor\n        \n    template_model.load_state_dict(soup_sd)\n    return template_model.to(CONFIG['device']).eval().float()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.801324Z","iopub.execute_input":"2026-01-29T12:41:45.801628Z","iopub.status.idle":"2026-01-29T12:41:45.819828Z","shell.execute_reply.started":"2026-01-29T12:41:45.801589Z","shell.execute_reply":"2026-01-29T12:41:45.818959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"class AkkadianTranslationDataset(Dataset):\n    def __init__(self, dataframe):\n        self.ids = dataframe['id'].tolist()\n        self.texts = [\n            \"translate Akkadian to English: \" \n            + str(t) for t in dataframe['transliteration']\n        ]\n    def __len__(self): return len(self.ids)\n    def __getitem__(self, idx): return self.ids[idx], self.texts[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.821265Z","iopub.execute_input":"2026-01-29T12:41:45.821982Z","iopub.status.idle":"2026-01-29T12:41:45.833605Z","shell.execute_reply.started":"2026-01-29T12:41:45.821935Z","shell.execute_reply":"2026-01-29T12:41:45.832947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataframe = pd.read_csv(CONFIG['data_path'])\ndataframe['transliteration'] = dataframe['transliteration'].apply(preprocess_transliteration)\n\nmodel = create_model_soup()\ntokenizer = AutoTokenizer.from_pretrained(CONFIG['models'][3])\n\ndata_loader = DataLoader(\n    AkkadianTranslationDataset(dataframe),\n    batch_size=CONFIG['batch_size'],\n    shuffle=False,\n    num_workers=2,\n    collate_fn=lambda batch: (\n        [item[0] for item in batch],\n        tokenizer(\n            [item[1] for item in batch], \n            max_length=CONFIG['max_len'], \n            padding=True, truncation=True, \n            return_tensors=\"pt\"\n        )\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:45.931448Z","iopub.execute_input":"2026-01-29T12:41:45.932172Z","iopub.status.idle":"2026-01-29T12:41:53.221827Z","shell.execute_reply.started":"2026-01-29T12:41:45.932139Z","shell.execute_reply":"2026-01-29T12:41:53.220918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_results = []\n\nwith torch.inference_mode():\n    for ids, inputs in data_loader:\n        outputs = model.generate(\n            input_ids=inputs.input_ids.to(CONFIG['device']),\n            attention_mask=inputs.attention_mask.to(CONFIG['device']),\n            **CONFIG['gen_params']\n        )\n        \n        decoded_texts = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        cleaned_translations = [postprocess_translation(text) for text in decoded_texts]\n        \n        inference_results.extend(zip(ids, cleaned_translations))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:53.223682Z","iopub.execute_input":"2026-01-29T12:41:53.224039Z","iopub.status.idle":"2026-01-29T12:41:57.542567Z","shell.execute_reply.started":"2026-01-29T12:41:53.223985Z","shell.execute_reply":"2026-01-29T12:41:57.541716Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"submission_df = pd.DataFrame(inference_results, columns=['id', 'translation'])\nsubmission_df.to_csv(\"submission.csv\", index=False)\nprint(submission_df.head(10).to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T12:41:57.543814Z","iopub.execute_input":"2026-01-29T12:41:57.544223Z","iopub.status.idle":"2026-01-29T12:41:57.554151Z","shell.execute_reply.started":"2026-01-29T12:41:57.544177Z","shell.execute_reply":"2026-01-29T12:41:57.553402Z"}},"outputs":[],"execution_count":null}]}